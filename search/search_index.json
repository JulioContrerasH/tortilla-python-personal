{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"index.html","text":"A python package for managing and validating your .tortilla data \ud83e\uded3 GitHub : https://github.com/tacofoundation/tortilla-python \ud83c\udf10 PyPI : https://pypi.org/project/pytortilla/ \ud83d\udee0\ufe0f Tortilla \ud83e\uded3 Hello! I'm a Tortilla, a format to serialize your EO data \ud83e\udd17. pytortilla is a Python package that simplifies the creation and management of .tortilla files\u2014these files are designed to encapsulate metadata, dataset information, and links to relevant files in remote sensing or AI workflows. This package is \u201cre-exported\u201d within tacotoolbox , specifically under tacotoolbox.tortilla . Therefore, by installing and using pytortilla , you can also leverage it from tacotoolbox.tortilla . Goals Metadata handling : Defines classes ( Sample , Samples ) to describe and structure your data\u2019s information. Dataset structuring : Easily generate training, validation, and testing splits, and store them in .tortilla files. Internal validation : Validate your dataset\u2019s integrity (e.g., opening each file with rasterio ). Integration with Earth Engine (ee) : Combines local data operations with GEE functionalities. Unified usage with tacotoolbox : Load and manipulate these datasets with tacoreader and other helper functions from tacotoolbox . Table of Contents Installation Usage guide Creating samples Validation and adding metadata Generating the .tortilla file Loading and using the .tortilla File Installation pip install pytortilla or from source: git clone https://github.com/tacofoundation/tortilla-python.git cd tortilla-python pip install . Note: You may also install it as part of tacotoolbox , where pytortilla is included as a dependency. Usage guide In this guide, we delve deeper into the step-by-step creation of .tortilla files, providing tips and best practices. import pathlib import rasterio import pandas as pd from sklearn.model_selection import train_test_split import pytortilla If you need Earth Engine: import ee ee . Initialize () # Requires prior authentication if not done already Files Move the Files from Hugging Face to Your Local Machine import os # URL path to the Hugging Face repository path = \"https://huggingface.co/datasets/tacofoundation/tortilla_demo/resolve/main/\" # List of demo files to download files = [ \"demo/high__test__ROI_0010__20190125T112341_20190125T112624_T28QFG.tif\" , \"demo/high__test__ROI_0011__20190130T103251_20190130T104108_T31REP.tif\" , \"demo/high__test__ROI_0011__20190830T102029_20190830T102552_T31REP.tif\" , \"demo/high__test__ROI_0064__20190317T015619_20190317T020354_T51JVH.tif\" , \"demo/high__test__ROI_0120__20191219T045209_20191219T045214_T45TXE.tif\" , \"demo/high__test__ROI_0141__20190316T141049_20190316T142437_T19FDE.tif\" , \"demo/high__test__ROI_0159__20200403T143721_20200403T144642_T19HBV.tif\" , \"demo/high__test__ROI_0235__20200402T053639_20200402T053638_T44UNV.tif\" ] # Create a local folder called 'demo' (if not already existing) os . system ( \"mkdir -p demo\" ) # Download each file to the 'demo' folder for file in files : os . system ( f \"wget { path }{ file } -O { file } \" ) Note: Depending on your environment, you might prefer using requests or urllib instead of os.system for downloading files. At this point, you should have a demo/ folder populated with several .tif files. Creating samples Now, we will create samples using pytortilla : import pathlib import pandas as pd from sklearn.model_selection import train_test_split import rasterio from pytortilla.datamodel import Sample , Samples # Define the local path containing the TIFF files demo_path = pathlib . Path ( \"./demo\" ) # Collect all .tif files in the demo folder all_files = list ( demo_path . glob ( \"*.tif\" )) # Split into train, val, and test train_files , test_files = train_test_split ( all_files , test_size = 0.2 , random_state = 42 ) train_files , val_files = train_test_split ( train_files , test_size = 0.2 , random_state = 42 ) train_df = pd . DataFrame ({ \"path\" : train_files , \"split\" : \"train\" }) val_df = pd . DataFrame ({ \"path\" : val_files , \"split\" : \"validation\" }) test_df = pd . DataFrame ({ \"path\" : test_files , \"split\" : \"test\" }) dataset_full = pd . concat ([ train_df , val_df , test_df ], ignore_index = True ) # Build a list of Sample objects samples_list = [] for _ , row in dataset_full . iterrows (): with rasterio . open ( row . path ) as src : metadata = src . profile sample_obj = Sample ( id = row . path . stem , path = str ( row . path ), file_format = \"GTiff\" , data_split = row . split , stac_data = { \"crs\" : str ( metadata [ \"crs\" ]), \"geotransform\" : metadata [ \"transform\" ] . to_gdal (), \"raster_shape\" : ( metadata [ \"height\" ], metadata [ \"width\" ]) } ) samples_list . append ( sample_obj ) samples_obj = Samples ( samples = samples_list ) Validation and adding metadata Validate each .tif file by trying to open it: samples_obj . deep_validator ( read_function = lambda x : rasterio . open ( x )) If you need RAI metadata (or any other additional metadata) in your workflow, you can include it: samples_obj = samples_obj . include_rai_metadata ( sample_footprint = 5120 , # Example footprint value cache = False , quiet = False ) Generating the .tortilla file Use pytortilla.create.main.create() (or the equivalent tacotoolbox.tortilla.create if you have tacotoolbox installed): from pytortilla.create.main import create # Generate the .tortilla file output_file = create ( samples = samples_obj , output = \"demo_dataset.tortilla\" ) print ( f \"Tortilla file generated: { output_file } \" ) The .tortilla might split into multiple files ( .0000.part.tortilla , etc.) for large datasets. Loading and using the .tortilla file Finally, load the .tortilla file (or its parts) with tacoreader: import tacoreader import pandas as pd dataset_chunks = [] # Try loading .part.tortilla files (assuming a maximum of 4 parts for this example) for i in range ( 4 ): part_file = f \"demo_dataset. { i : 04d } .part.tortilla\" try : dataset_part = tacoreader . load ( part_file ) dataset_chunks . append ( dataset_part ) except FileNotFoundError : break # Stop if no more parts if dataset_chunks : dataset = pd . concat ( dataset_chunks , ignore_index = True ) print ( dataset . head ()) else : print ( \"No tortilla parts found.\" )","title":"Index"},{"location":"index.html#_1","text":"A python package for managing and validating your .tortilla data \ud83e\uded3 GitHub : https://github.com/tacofoundation/tortilla-python \ud83c\udf10 PyPI : https://pypi.org/project/pytortilla/ \ud83d\udee0\ufe0f","title":""},{"location":"index.html#tortilla","text":"Hello! I'm a Tortilla, a format to serialize your EO data \ud83e\udd17. pytortilla is a Python package that simplifies the creation and management of .tortilla files\u2014these files are designed to encapsulate metadata, dataset information, and links to relevant files in remote sensing or AI workflows. This package is \u201cre-exported\u201d within tacotoolbox , specifically under tacotoolbox.tortilla . Therefore, by installing and using pytortilla , you can also leverage it from tacotoolbox.tortilla .","title":"Tortilla \ud83e\uded3"},{"location":"index.html#goals","text":"Metadata handling : Defines classes ( Sample , Samples ) to describe and structure your data\u2019s information. Dataset structuring : Easily generate training, validation, and testing splits, and store them in .tortilla files. Internal validation : Validate your dataset\u2019s integrity (e.g., opening each file with rasterio ). Integration with Earth Engine (ee) : Combines local data operations with GEE functionalities. Unified usage with tacotoolbox : Load and manipulate these datasets with tacoreader and other helper functions from tacotoolbox .","title":"Goals"},{"location":"index.html#table-of-contents","text":"Installation Usage guide Creating samples Validation and adding metadata Generating the .tortilla file Loading and using the .tortilla File","title":"Table of Contents"},{"location":"index.html#installation","text":"pip install pytortilla or from source: git clone https://github.com/tacofoundation/tortilla-python.git cd tortilla-python pip install . Note: You may also install it as part of tacotoolbox , where pytortilla is included as a dependency.","title":"Installation"},{"location":"index.html#usage-guide","text":"In this guide, we delve deeper into the step-by-step creation of .tortilla files, providing tips and best practices. import pathlib import rasterio import pandas as pd from sklearn.model_selection import train_test_split import pytortilla If you need Earth Engine: import ee ee . Initialize () # Requires prior authentication if not done already","title":"Usage guide"},{"location":"index.html#files","text":"Move the Files from Hugging Face to Your Local Machine import os # URL path to the Hugging Face repository path = \"https://huggingface.co/datasets/tacofoundation/tortilla_demo/resolve/main/\" # List of demo files to download files = [ \"demo/high__test__ROI_0010__20190125T112341_20190125T112624_T28QFG.tif\" , \"demo/high__test__ROI_0011__20190130T103251_20190130T104108_T31REP.tif\" , \"demo/high__test__ROI_0011__20190830T102029_20190830T102552_T31REP.tif\" , \"demo/high__test__ROI_0064__20190317T015619_20190317T020354_T51JVH.tif\" , \"demo/high__test__ROI_0120__20191219T045209_20191219T045214_T45TXE.tif\" , \"demo/high__test__ROI_0141__20190316T141049_20190316T142437_T19FDE.tif\" , \"demo/high__test__ROI_0159__20200403T143721_20200403T144642_T19HBV.tif\" , \"demo/high__test__ROI_0235__20200402T053639_20200402T053638_T44UNV.tif\" ] # Create a local folder called 'demo' (if not already existing) os . system ( \"mkdir -p demo\" ) # Download each file to the 'demo' folder for file in files : os . system ( f \"wget { path }{ file } -O { file } \" ) Note: Depending on your environment, you might prefer using requests or urllib instead of os.system for downloading files. At this point, you should have a demo/ folder populated with several .tif files.","title":"Files"},{"location":"index.html#creating-samples","text":"Now, we will create samples using pytortilla : import pathlib import pandas as pd from sklearn.model_selection import train_test_split import rasterio from pytortilla.datamodel import Sample , Samples # Define the local path containing the TIFF files demo_path = pathlib . Path ( \"./demo\" ) # Collect all .tif files in the demo folder all_files = list ( demo_path . glob ( \"*.tif\" )) # Split into train, val, and test train_files , test_files = train_test_split ( all_files , test_size = 0.2 , random_state = 42 ) train_files , val_files = train_test_split ( train_files , test_size = 0.2 , random_state = 42 ) train_df = pd . DataFrame ({ \"path\" : train_files , \"split\" : \"train\" }) val_df = pd . DataFrame ({ \"path\" : val_files , \"split\" : \"validation\" }) test_df = pd . DataFrame ({ \"path\" : test_files , \"split\" : \"test\" }) dataset_full = pd . concat ([ train_df , val_df , test_df ], ignore_index = True ) # Build a list of Sample objects samples_list = [] for _ , row in dataset_full . iterrows (): with rasterio . open ( row . path ) as src : metadata = src . profile sample_obj = Sample ( id = row . path . stem , path = str ( row . path ), file_format = \"GTiff\" , data_split = row . split , stac_data = { \"crs\" : str ( metadata [ \"crs\" ]), \"geotransform\" : metadata [ \"transform\" ] . to_gdal (), \"raster_shape\" : ( metadata [ \"height\" ], metadata [ \"width\" ]) } ) samples_list . append ( sample_obj ) samples_obj = Samples ( samples = samples_list )","title":"Creating samples"},{"location":"index.html#validation-and-adding-metadata","text":"Validate each .tif file by trying to open it: samples_obj . deep_validator ( read_function = lambda x : rasterio . open ( x )) If you need RAI metadata (or any other additional metadata) in your workflow, you can include it: samples_obj = samples_obj . include_rai_metadata ( sample_footprint = 5120 , # Example footprint value cache = False , quiet = False )","title":"Validation and adding metadata"},{"location":"index.html#generating-the-tortilla-file","text":"Use pytortilla.create.main.create() (or the equivalent tacotoolbox.tortilla.create if you have tacotoolbox installed): from pytortilla.create.main import create # Generate the .tortilla file output_file = create ( samples = samples_obj , output = \"demo_dataset.tortilla\" ) print ( f \"Tortilla file generated: { output_file } \" ) The .tortilla might split into multiple files ( .0000.part.tortilla , etc.) for large datasets.","title":"Generating the .tortilla file"},{"location":"index.html#loading-and-using-the-tortilla-file","text":"Finally, load the .tortilla file (or its parts) with tacoreader: import tacoreader import pandas as pd dataset_chunks = [] # Try loading .part.tortilla files (assuming a maximum of 4 parts for this example) for i in range ( 4 ): part_file = f \"demo_dataset. { i : 04d } .part.tortilla\" try : dataset_part = tacoreader . load ( part_file ) dataset_chunks . append ( dataset_part ) except FileNotFoundError : break # Stop if no more parts if dataset_chunks : dataset = pd . concat ( dataset_chunks , ignore_index = True ) print ( dataset . head ()) else : print ( \"No tortilla parts found.\" )","title":"Loading and using the .tortilla file"},{"location":"CHANGELOG.html","text":"Changelog All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning . [Unreleased] Added Initial release of SuperS2 with core functionalities for Sentinel-2 data processing. Detailed documentation for installation and basic usage examples. Changed Updated README to include new badges and links. Fixed Fixed minor bugs in the data processing module related to edge cases. [0.0.7] - 2024-10-24 Added First public release with support for enhancing Sentinel-2 spatial resolution to 2.5 meters.","title":"Changelog"},{"location":"CHANGELOG.html#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog , and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"CHANGELOG.html#unreleased","text":"","title":"[Unreleased]"},{"location":"CHANGELOG.html#added","text":"Initial release of SuperS2 with core functionalities for Sentinel-2 data processing. Detailed documentation for installation and basic usage examples.","title":"Added"},{"location":"CHANGELOG.html#changed","text":"Updated README to include new badges and links.","title":"Changed"},{"location":"CHANGELOG.html#fixed","text":"Fixed minor bugs in the data processing module related to edge cases.","title":"Fixed"},{"location":"CHANGELOG.html#007-2024-10-24","text":"","title":"[0.0.7] - 2024-10-24"},{"location":"CHANGELOG.html#added_1","text":"First public release with support for enhancing Sentinel-2 spatial resolution to 2.5 meters.","title":"Added"},{"location":"CODE_OF_CONDUCT.html","text":"Contributor covenant code of conduct \ud83d\udcdc Our pledge \ud83e\udd1d In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17 Our standards \ud83d\udccf Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54 Our responsibilities \ud83d\udee1\ufe0f Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \ud83c\udf10 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \ud83d\udea8 All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \ud83d\udc4f This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Code of conduct"},{"location":"CODE_OF_CONDUCT.html#contributor-covenant-code-of-conduct","text":"","title":"Contributor covenant code of conduct \ud83d\udcdc"},{"location":"CODE_OF_CONDUCT.html#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation. \ud83c\udf0e\ud83e\udd17","title":"Our pledge \ud83e\udd1d"},{"location":"CODE_OF_CONDUCT.html#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language. \ud83d\ude0a Being respectful of differing viewpoints and experiences. \ud83e\udd14\ud83d\udc42 Gracefully accepting constructive criticism. \ud83d\udee0\ufe0f Focusing on what is best for the community. \ud83e\udd32 Showing empathy towards other community members. \ud83e\udd7a\u2764\ufe0f Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances. \ud83d\udeab\ud83d\udcac Trolling, insulting/derogatory comments, and personal or political attacks. \ud83d\udeab\ud83d\ude20 Public or private harassment. \ud83d\udeab\ud83d\udc65 Publishing others' private information, such as a physical or electronic address, without explicit permission. \ud83d\udeab\ud83c\udfe1 Other conduct which could reasonably be considered inappropriate in a professional setting. \ud83d\udeab\ud83d\udc54","title":"Our standards \ud83d\udccf"},{"location":"CODE_OF_CONDUCT.html#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our responsibilities \ud83d\udee1\ufe0f"},{"location":"CODE_OF_CONDUCT.html#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope \ud83c\udf10"},{"location":"CODE_OF_CONDUCT.html#enforcement","text":"All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement \ud83d\udea8"},{"location":"CODE_OF_CONDUCT.html#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html For answers to common questions about this code of conduct, see https://www.contributor-covenant.org/faq","title":"Attribution \ud83d\udc4f"},{"location":"CONTRIBUTING.html","text":"Contributing to tortilla-spec Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways: Types of Contributions Report Bugs Report bugs at https://github.com/csaybar/tortilla-spec/issues If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug. Fix Bugs Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement a fix for it. Implement Features Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it. Write Documentation Cookiecutter PyPackage could always use more documentation, whether as part of the official docs, in docstrings, or even on the web in blog posts, articles, and such. Submit Feedback The best way to send feedback is to file an issue at https://github.com/csaybar/tortilla-spec/issues. If you are proposing a new feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :) Get Started! Ready to contribute? Here's how to set up tortilla-spec for local development. Please note this documentation assumes you already have poetry and Git installed and ready to go. Fork the tortilla-spec repo on GitHub. Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone git@github.com:YOUR_NAME/tortilla-spec.git Now we need to install the environment. Navigate into the directory cd tortilla-spec If you are using pyenv , select a version to use locally. (See installed versions with pyenv versions ) pyenv local <x.y.z> Then, install and activate the environment with: poetry install poetry shell Install pre-commit to run linters/formatters at commit time: poetry run pre-commit install Create a branch for local development: git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. Don't forget to add test cases for your added functionality to the tests directory. When you're done making changes, check that your changes pass the formatting tests. make check Now, validate that all unit tests are passing: make test Before raising a pull request you should also run tox. This will run the tests across different versions of Python: tox This requires you to have multiple versions of python installed. This step is also triggered in the CI/CD pipeline, so you could also choose to skip this step locally. Commit your changes and push your branch to GitHub: git add . git commit -m \"Your detailed description of your changes.\" git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website. Pull Request Guidelines Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md .","title":"Contributing"},{"location":"CONTRIBUTING.html#contributing-to-tortilla-spec","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. You can contribute in many ways:","title":"Contributing to tortilla-spec"},{"location":"CONTRIBUTING.html#types-of-contributions","text":"","title":"Types of Contributions"},{"location":"CONTRIBUTING.html#report-bugs","text":"Report bugs at https://github.com/csaybar/tortilla-spec/issues If you are reporting a bug, please include: Your operating system name and version. Any details about your local setup that might be helpful in troubleshooting. Detailed steps to reproduce the bug.","title":"Report Bugs"},{"location":"CONTRIBUTING.html#fix-bugs","text":"Look through the GitHub issues for bugs. Anything tagged with \"bug\" and \"help wanted\" is open to whoever wants to implement a fix for it.","title":"Fix Bugs"},{"location":"CONTRIBUTING.html#implement-features","text":"Look through the GitHub issues for features. Anything tagged with \"enhancement\" and \"help wanted\" is open to whoever wants to implement it.","title":"Implement Features"},{"location":"CONTRIBUTING.html#write-documentation","text":"Cookiecutter PyPackage could always use more documentation, whether as part of the official docs, in docstrings, or even on the web in blog posts, articles, and such.","title":"Write Documentation"},{"location":"CONTRIBUTING.html#submit-feedback","text":"The best way to send feedback is to file an issue at https://github.com/csaybar/tortilla-spec/issues. If you are proposing a new feature: Explain in detail how it would work. Keep the scope as narrow as possible, to make it easier to implement. Remember that this is a volunteer-driven project, and that contributions are welcome :)","title":"Submit Feedback"},{"location":"CONTRIBUTING.html#get-started","text":"Ready to contribute? Here's how to set up tortilla-spec for local development. Please note this documentation assumes you already have poetry and Git installed and ready to go. Fork the tortilla-spec repo on GitHub. Clone your fork locally: cd <directory_in_which_repo_should_be_created> git clone git@github.com:YOUR_NAME/tortilla-spec.git Now we need to install the environment. Navigate into the directory cd tortilla-spec If you are using pyenv , select a version to use locally. (See installed versions with pyenv versions ) pyenv local <x.y.z> Then, install and activate the environment with: poetry install poetry shell Install pre-commit to run linters/formatters at commit time: poetry run pre-commit install Create a branch for local development: git checkout -b name-of-your-bugfix-or-feature Now you can make your changes locally. Don't forget to add test cases for your added functionality to the tests directory. When you're done making changes, check that your changes pass the formatting tests. make check Now, validate that all unit tests are passing: make test Before raising a pull request you should also run tox. This will run the tests across different versions of Python: tox This requires you to have multiple versions of python installed. This step is also triggered in the CI/CD pipeline, so you could also choose to skip this step locally. Commit your changes and push your branch to GitHub: git add . git commit -m \"Your detailed description of your changes.\" git push origin name-of-your-bugfix-or-feature Submit a pull request through the GitHub website.","title":"Get Started!"},{"location":"CONTRIBUTING.html#pull-request-guidelines","text":"Before you submit a pull request, check that it meets these guidelines: The pull request should include tests. If the pull request adds functionality, the docs should be updated. Put your new functionality into a function with a docstring, and add the feature to the list in README.md .","title":"Pull Request Guidelines"}]}